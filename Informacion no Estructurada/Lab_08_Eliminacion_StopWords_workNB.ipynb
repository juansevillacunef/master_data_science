{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eliminación de palabras vacías (stop-words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Importación de librerías. Importa nltk y spacy\n",
    "\n",
    "import time\n",
    "import nltk\n",
    "import spacy\n",
    "\n",
    "# cargamos modelo de tokenizacion para nltk, y de stopwords\n",
    "tokenizer = nltk.data.load(\"tokenizers/punkt/spanish.pickle\")\n",
    "stopwords = nltk.corpus.stopwords.words('spanish')\n",
    "\n",
    "### carga el modelo es_core_news_lg de spacy\n",
    "######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Genera una función que lea un fichero txt\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pasos a seguir con NLTK\n",
    "1. Tokenización del texto (separar en palabras)\n",
    "2. Filtrado de la lista de palabras, para excluir aquellas que estén en la lista de stopwords (generada en la primera celda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Pues', 'sepa', 'V.M', '.', 'ante', 'todas', 'cosas', 'que', 'a', 'mí', 'llaman', 'Lázaro', 'de', 'Tormes', ',', 'hijo', 'de', 'Tomé', 'González', 'y', 'de', 'Antona', 'Pérez', ',', 'naturales', 'de', 'Tejares', ',', 'aldea', 'de']\n",
      "['Pues', 'sepa', 'V.M', '.', 'todas', 'cosas', 'llaman', 'Lázaro', 'Tormes', ',', 'hijo', 'Tomé', 'González', 'Antona', 'Pérez', ',', 'naturales', 'Tejares', ',', 'aldea', 'Salamanca', '.', 'nacimiento', 'dentro', 'río', 'Tormes', ',', 'causa', 'tomé', 'sobrenombre']\n"
     ]
    }
   ],
   "source": [
    "### Principal. Lee el archivo de lazarillo\n",
    "\n",
    "lazarillo_text = read_text_file(\"data/Lazarillo.txt\")\n",
    "\n",
    "# tokeniza el texto con nltk\n",
    "words = nltk.word_tokenize(lazarillo_text)\n",
    "print(words[:30])\n",
    "\n",
    "# filtra la lista de palabras para excluir las que son stop_words\n",
    "words = [word for word in words if word.lower() not in stopwords]\n",
    "print(words[:30])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pasos a seguir con Spacy\n",
    "1. Generación del doc (si recorremos doc con un for, ya tenemos los tokens).\n",
    "2. Filtrado de la lista de palabras, para excluir aquellas que tengan la etiqueta de stop word (en cada palabra del texto, .is_stop es True si lo es))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[sepa, V.M., \n",
      ", a, llaman, Lázaro, Tormes, ,, hijo, Tomé, González, y, Antona, Pérez, ,, naturales, Tejares, ,, aldea, Salamanca, ., \n",
      ", nacimiento, río, Tormes, ,, causa, tomé, sobrenombre, ,]\n"
     ]
    }
   ],
   "source": [
    "### Eliminación stopwords - spaCy\n",
    "\n",
    "# genera el doc \n",
    "doc = nlp(lazarillo_text)\n",
    "\n",
    "# filtra el listado de palabras utilizando .is_stop\n",
    "words = [word for word in doc if not word.is_stop]\n",
    "print(words[:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "107fb03afb2754bdb3cdbb13c1c83d7d6037442339c22e5ee8cf40869e8513c5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
