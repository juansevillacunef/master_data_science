{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part of Speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importación de librerías. Importa nltk y spacy\n",
    "\n",
    "import nltk\n",
    "import spacy\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "### carga el modelo es_core_news_lg de spacy\n",
    "nlp = spacy.load(\"es_core_news_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Genera una función que lea un fichero txt\n",
    "\n",
    "def read_text_file(filename):\n",
    "    file = open(filename, \"r\", encoding=\"utf-8\") \n",
    "    return file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Lee el archivo Lazarillo\n",
    "\n",
    "lazarillo_text = read_text_file(\"data/Lazarillo.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POS - NLTK\n",
      "[[('Pues', 'NNS'), ('sepa', 'VBP'), ('V.M', 'NNP'), ('.', '.'), ('ante', 'NN'), ('todas', 'JJ'), ('cosas', 'NN'), ('que', 'NN'), ('a', 'DT'), ('mí', 'NN'), ('llaman', 'JJ'), ('Lázaro', 'NNP'), ('de', 'FW'), ('Tormes', 'NNP'), (',', ','), ('hijo', 'NN'), ('de', 'FW'), ('Tomé', 'NNP'), ('González', 'NNP'), ('y', 'NNP'), ('de', 'IN'), ('Antona', 'NNP'), ('Pérez', 'NNP'), (',', ','), ('naturales', 'FW'), ('de', 'FW'), ('Tejares', 'NNP'), (',', ','), ('aldea', 'NN'), ('de', 'FW'), ('Salamanca', 'NNP'), ('.', '.'), ('Mi', 'NNP'), ('nacimiento', 'IN'), ('fue', 'JJ'), ('dentro', 'NN'), ('del', 'NN'), ('río', 'NN'), ('Tormes', 'NNP'), (',', ','), ('por', 'NN'), ('la', 'FW'), ('cual', 'JJ'), ('causa', 'NN'), ('tomé', 'NN'), ('el', 'NN'), ('sobrenombre', 'NN'), (',', ','), ('y', 'CC'), ('fue', 'JJ'), ('desta', 'NN'), ('manera', 'NN'), ('.', '.'), ('Mi', 'NNP'), ('padre', 'NN'), (',', ','), ('que', 'JJ'), ('Dios', 'NNP'), ('perdone', 'NN'), (',', ','), ('tenía', 'JJ'), ('cargo', 'NN'), ('de', 'IN'), ('proveer', 'FW'), ('una', 'JJ'), ('molienda', 'NN'), ('de', 'IN'), ('una', 'JJ'), ('aceña', 'NN'), (',', ','), ('que', 'JJ'), ('está', 'FW'), ('ribera', 'NN'), ('de', 'IN'), ('aquel', 'FW'), ('río', 'NN'), (',', ','), ('en', 'FW'), ('la', 'FW'), ('cual', 'JJ'), ('fue', 'NN'), ('molinero', 'NN'), ('más', 'NN'), ('de', 'FW'), ('quince', 'NN'), ('años', 'NN'), (';', ':'), ('y', 'CC'), ('estando', 'VB'), ('mi', 'NN'), ('madre', 'NN'), ('una', 'JJ'), ('noche', 'NN'), ('en', 'IN'), ('la', 'FW'), ('aceña', 'FW'), (',', ','), ('preñada', 'FW'), ('de', 'FW'), ('mí', 'FW'), (',', ','), ('tomóle', 'EX'), ('el', 'FW'), ('parto', 'NN'), ('y', 'NN'), ('parióme', 'NN'), ('allí', 'NN'), (':', ':'), ('de', 'FW'), ('manera', 'FW'), ('que', 'NN'), ('con', 'NN'), ('verdad', 'NN'), ('puedo', 'NN'), ('decir', 'NN'), ('nacido', 'NN'), ('en', 'IN'), ('el', 'NN'), ('río', 'NN'), ('.', '.'), ('Pues', 'NNP'), ('siendo', 'VBD'), ('yo', 'JJ'), ('niño', 'FW'), ('de', 'FW'), ('ocho', 'FW'), ('años', 'NN'), (',', ','), ('achacaron', 'VBZ'), ('a', 'DT'), ('mi', 'NN'), ('padre', 'NN'), ('ciertas', 'NNS'), ('sangrías', 'VBP'), ('mal', 'JJ'), ('hechas', 'NN'), ('en', 'FW'), ('los', 'NN'), ('costales', 'NNS'), ('de', 'IN'), ('los', 'FW'), ('que', 'JJ'), ('allí', 'NN'), ('a', 'DT'), ('moler', 'NN'), ('venían', 'NN'), (',', ','), ('por', 'NN'), ('lo', 'NN'), ('que', 'NN'), ('fue', 'NN'), ('preso', 'NN'), (',', ','), ('y', 'CC'), ('confesó', 'NN'), ('y', 'NN'), ('no', 'DT'), ('negó', 'JJ'), ('y', 'NN'), ('padeció', 'NN'), ('persecución', 'NN'), ('por', 'NN'), ('justicia', 'NN'), ('.', '.'), ('Espero', 'NNP'), ('en', 'IN'), ('Dios', 'NNP'), ('que', 'NN'), ('está', 'NN'), ('en', 'IN'), ('la', 'FW'), ('Gloria', 'NNP'), (',', ','), ('pues', 'VBZ'), ('el', 'VBP'), ('Evangelio', 'NNP'), ('los', 'NN'), ('llama', 'NN'), ('bienaventurados', 'NN'), ('.', '.'), ('En', 'NNP'), ('este', 'NN'), ('tiempo', 'NN'), ('se', 'NN'), ('hizo', 'NN'), ('cierta', 'NN'), ('armada', 'NN'), ('contra', 'NN'), ('moros', 'NNS'), (',', ','), ('entre', 'FW'), ('los', 'JJ'), ('cuales', 'NNS'), ('fue', 'VBP'), ('mi', 'JJ'), ('padre', 'NN'), (',', ','), ('que', 'VBZ'), ('a', 'DT'), ('la', 'NN'), ('sazón', 'NN'), ('estaba', 'NN'), ('desterrado', 'NN'), ('por', 'NN'), ('el', 'NN'), ('desastre', 'NN'), ('ya', 'NN'), ('dicho', 'NN'), (',', ','), ('con', 'JJ'), ('cargo', 'NN'), ('de', 'IN'), ('acemilero', 'FW'), ('de', 'FW'), ('un', 'FW'), ('caballero', 'NN'), ('que', 'NN'), ('allá', 'NN'), ('fue', 'NN'), (',', ','), ('y', 'JJ'), ('con', 'NN'), ('su', 'NN'), ('señor', 'NN'), (',', ','), ('como', 'NN'), ('leal', 'NN'), ('criado', 'NN'), (',', ','), ('feneció', 'JJ'), ('su', 'NN'), ('vida', 'NN'), ('.', '.')]]\n"
     ]
    }
   ],
   "source": [
    "### POS - NLTK\n",
    "print(\"POS - NLTK\")\n",
    "\n",
    "# genera la lista de tokens\n",
    "tokens = [nltk.word_tokenize(lazarillo_text)]\n",
    "\n",
    "# aplica a cada token (con un bucle for) la etiqueta POS_TAG correspondiente con .pos_tag()\n",
    "pos=[]\n",
    "for token in tokens:\n",
    "    pos.append(nltk.pos_tag(token))\n",
    "\n",
    "print(pos[:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POS - spaCy\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Palabra</th>\n",
       "      <td>Pues</td>\n",
       "      <td>sepa</td>\n",
       "      <td>V.M.</td>\n",
       "      <td>\\n</td>\n",
       "      <td>ante</td>\n",
       "      <td>todas</td>\n",
       "      <td>cosas</td>\n",
       "      <td>que</td>\n",
       "      <td>a</td>\n",
       "      <td>mí</td>\n",
       "      <td>llaman</td>\n",
       "      <td>Lázaro</td>\n",
       "      <td>de</td>\n",
       "      <td>Tormes</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Part of Spech</th>\n",
       "      <td>SCONJ</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>SPACE</td>\n",
       "      <td>ADP</td>\n",
       "      <td>DET</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>SCONJ</td>\n",
       "      <td>ADP</td>\n",
       "      <td>PRON</td>\n",
       "      <td>VERB</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>ADP</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>PUNCT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0      1      2      3     4      5      6      7    8   \\\n",
       "Palabra         Pues   sepa   V.M.     \\n  ante  todas  cosas    que    a   \n",
       "Part of Spech  SCONJ  PROPN  PROPN  SPACE   ADP    DET   NOUN  SCONJ  ADP   \n",
       "\n",
       "                 9       10      11   12      13     14  \n",
       "Palabra          mí  llaman  Lázaro   de  Tormes      ,  \n",
       "Part of Spech  PRON    VERB   PROPN  ADP   PROPN  PUNCT  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### POS - spaCy\n",
    "print(\"POS - spaCy\")\n",
    "\n",
    "# genera el doc\n",
    "doc = nlp(lazarillo_text)\n",
    "\n",
    "# aplica el POS_TAG a cada palabra\n",
    "tokens_tagged = [(palabra.text, palabra.pos_) for palabra in doc]\n",
    "df=pd.DataFrame(tokens_tagged, columns=['Palabra', 'Part of Spech']).T\n",
    "df.iloc[:,:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "144.844px",
    "left": "935px",
    "right": "20px",
    "top": "18px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  },
  "vscode": {
   "interpreter": {
    "hash": "107fb03afb2754bdb3cdbb13c1c83d7d6037442339c22e5ee8cf40869e8513c5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
